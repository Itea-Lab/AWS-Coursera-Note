# Module 4:
## A) Lecture Notes: Monitoring on AWS**

**I. Introduction: The Importance of Monitoring**

*   **Context:** Modern AWS solutions are built from many interconnected services (e.g., EC2, RDS, DynamoDB, S3).  Understanding how these services operate individually and as a system is crucial.
*   **Problem:**
    *   User-reported issues (latency, errors) are a *reactive* approach, leading to user dissatisfaction.
    *   Users can't provide insights into the *root cause* of problems (EC2? Database? Code?).
    *   Without monitoring, troubleshooting is slow and difficult (digging through logs, guesswork).
*   **Solution: Proactive Monitoring**
    *   **Definition:** Monitoring is the *active* process of collecting and analyzing data (metrics, logs, network traffic) from your infrastructure and applications.
    *   **Goal:** Identify and respond to operational issues *before* they impact users.  Provide a deep understanding of system health.
    *   **Key Idea:** In a dynamic cloud environment (scaling up/down), continuous monitoring is essential.
    * Analize data in near real-time.

**II. Understanding Metrics and Statistics**

*   **Metrics:**
    *   Definition: Individual data points generated by AWS resources.  Examples:
        *   EC2: CPU Utilization, Network Traffic, Disk I/O
        *   RDS: Database Connections, CPU Utilization, Disk Space
        *   S3: Bucket Size, Number of Objects, Request Metrics (GET, PUT)
    *   Each service generates its own relevant metrics.
*   **Statistics:**
    *   Definition: Metrics analyzed *over time*.  Example: Average CPU utilization over the last hour, showing trends and spikes.
    *   Usefulness: Helps establish *baselines* of normal operation. Deviations from the baseline indicate potential problems.

**III. The Benefits of Monitoring**

*   **Proactive Issue Response:**
    *   Detect problems (high error rates, latency) *before* users notice.
    *   Enable automated or manual actions to prevent outages.
*   **Performance and Reliability Improvement:**
    *   Identify bottlenecks and inefficiencies in your architecture.
    *   Guide optimization efforts for a smoother user experience.
*   **Security Threat Recognition:**
    *   Establish a baseline of normal activity.
    *   Detect anomalies (unusual traffic, unexpected access) that might indicate security breaches.
    *   Trigger alerts for investigation.
*   **Data-Driven Business Decisions:**
    *   Track application-level metrics (e.g., feature usage).
    *   Inform decisions about feature development and resource allocation.
*   **Cost Optimization:**
    *   Identify underutilized resources.
    *   Right-size your infrastructure to save money.
*   **Visibility:**
    * See the data of the distributed system on a centralized platform.

**IV. Introduction to Amazon CloudWatch**

*   **Centralized Monitoring:** CloudWatch is AWS's managed monitoring and observability service.  It provides a single place to collect and analyze data from various AWS resources.
*   **Key Features:**
    *   **Data Collection:** Automatically collects metrics from many AWS services (EC2, RDS, DynamoDB, etc.).
    *   **Actionable Insights:** Provides tools to understand application performance and system-wide health.
    *   **Unified View:** Combines data from multiple sources for a holistic perspective.
    *   **Anomaly Detection:** Identify unusual behavior.
    *   **Alarms:** Set thresholds and trigger alerts/actions.
    *   **Visualization:** View logs and metrics in the AWS Management Console.
    *   **Automated Actions:** Trigger actions like scaling based on metrics.
    *   **Troubleshooting:** Diagnose and resolve issues.
    *   **Application Health:** Keep applications running smoothly.

**V. CloudWatch Features and Use Cases (Demo Walkthrough)**

*   **Dashboards:**
    *   **Purpose:** Customizable pages in the CloudWatch console to monitor resources in a single view (even across regions).
    *   **Creation:**
        1.  Navigate to CloudWatch in the AWS Management Console.
        2.  Create a new dashboard.
        3.  Add widgets (e.g., line graphs) to visualize metrics.
        4.  Select data sources (e.g., EC2 CPU Utilization).
        5.  Customize the dashboard's appearance and settings.
    *   **Custom Metrics:**  You can programmatically report custom metrics to CloudWatch for application-specific monitoring (e.g., page views, error rates).  This provides a more complete picture of application health.
    * **Sharing:**
        * Share the dashboards with others.
*   **Alarms:**
    *   **Purpose:** Create thresholds for metrics. Trigger actions when thresholds are breached.
    *   **States:**
        *   **OK:** Metric is within the defined threshold.
        *   **ALARM:** Metric has crossed the threshold.
        *   **INSUFFICIENT_DATA:** Not enough data to determine the state.
    *   **Creation:**
        1.  Navigate to the Alarms section in CloudWatch.
        2.  Create a new alarm.
        3.  Select the metric (e.g., EC2 CPU Utilization).
        4.  Define the threshold (e.g., > 70%).
        5.  Set the time period for evaluation (e.g., 5 minutes).
        6.  Configure actions (e.g., send an SNS notification).
    *   **Actions:**
        *   **SNS Notifications:** Send emails, SMS messages, or trigger other services.  This is useful for alerting on-call personnel.
        *   **EC2 Actions:** Reboot, stop, or terminate an instance.
        *   **Auto Scaling Actions:** Scale resources up or down.
        * **Lambda Functions** Call any AWS API to manage your resources.

**VI. Deep Dive into CloudWatch Concepts (Reading 4.2)**

*   **How CloudWatch Works:**
    *   Managed service â€“ no infrastructure to manage.
    *   Centralized data collection from AWS services.
    *   Basic monitoring (5-minute intervals) is often free.
    *   Detailed monitoring (1-minute intervals) is available (extra cost).
*   **Metric Details:**
    *   **Namespaces:** Containers for metrics (like categories).  Metrics in different namespaces are isolated.
    *   **Dimensions:** Name/value pairs that identify a specific metric (e.g., InstanceId for EC2).  Used for filtering.
*   **Custom Metrics:**
    *   Publish your own application-level metrics.
    *   High-resolution custom metrics (down to 1-second resolution).
    *   Use the `PutMetricData` API.
*   **CloudWatch Dashboards (Further Details):**
    *   Customizable home pages.
    *   Multiple widgets (graphs, text).
    *   Cross-region data aggregation.
    *   Live data (data from the last minute).
    *   Integration with external tools via `GetMetricData` API.
    *   Access control via IAM.
*   **CloudWatch Logs:**
    *   Centralized log storage and analysis.
    *   Query and filter log data.
    *   Metric filters: Turn log data into numerical metrics.
    *   Integration with services like Lambda (easy) and EC2 (requires agent installation).
    *   **Log Terminology:**
        *   **Log Event:** A single log record.
        *   **Log Stream:** A sequence of log events from the same resource.
        *   **Log Group:** A collection of log streams with shared settings.
* **CloudWatch Alarms in practice:**
    * Turn log data into metrics.
    * Set up notifications or automations.

**VII. Conclusion**

*   Monitoring is essential for building reliable, performant, secure, and cost-effective solutions on AWS.
*   Amazon CloudWatch is a powerful tool for centralized monitoring, providing a comprehensive view of your AWS resources and applications.
*   By understanding metrics, alarms, dashboards, and logs, you can proactively manage your AWS environment and ensure a positive experience for your users.


## B) Lecture Title: Optimization: Enhancing Availability, Scalability, and Efficiency in AWS

**I. Introduction: Beyond Basic Monitoring**

*   **Initial Setup:** We've previously learned how to set up alarms (using CloudWatch) to monitor infrastructure capacity, performance, and availability.
*   **The Next Step:**  The goal is to move beyond *notification* to *prevention* and *automated response*.
*   **Current Infrastructure (Baseline):**
    *   Single EC2 instance hosting the "Employee Directory" application.
    *   DynamoDB for structured data (highly available by design).
    *   Amazon S3 for static asset storage (highly available by design).
    *   Single point of failure: The EC2 instance. If it fails, the application is inaccessible.

**II.  Availability: The Foundation of Optimization**

*   **Definition of Availability:**  Expressed as a percentage of uptime over a year, often represented as "nines" (e.g., 99.9% = "three nines").
    *   See the provided table for downtime per year associated with each "nine" level.
*   **The Core Principle: Redundancy**
    *   Higher availability requires redundant infrastructure (more servers, data centers, databases, data replication).
    *   **Cost-Benefit Analysis:**  Adding redundancy increases cost.  The key is to find the balance between desired availability and financial viability.  There's a point where adding more redundancy provides diminishing returns.
*    **Improving Application Availability**
    *     Single point of failure with only one EC2 instance
    *     Adding one or more servers to eliminate it.

**III. Achieving Redundancy: Multiple Instances and Availability Zones**

*   **Adding a Second Instance:** The simplest way to increase availability is to add a second EC2 instance running the same application.
*   **Importance of Location: Availability Zones (AZs)**
    *   **Physical Isolation:**  The second instance *must* be in a *different* Availability Zone. This protects against failures affecting an entire AZ (e.g., power outage, natural disaster).
    *   **Mitigating Risks:**  AZ separation mitigates risks at multiple levels: hardware, server rack, data center, and the AZ itself.
*   **New Challenges with Multiple Instances:**
    *   **Replication:**  Maintaining identical configurations (software, patches, application code) across instances.  Automation is crucial.
    *   **Redirection:**  How do clients (users' browsers) know which server to connect to?
        *   **DNS:**  Possible, but propagation delays (time for DNS updates to spread) can be an issue.
        *   **Load Balancer (Preferred):**  A load balancer sits between clients and servers, handling health checks and distributing traffic.  Eliminates propagation delays.
    *   **High Availability Types:**
        *   **Active-Passive:** Only one instance is active at a time.  Simpler for stateful applications (where session data is stored on the server).
        *   **Active-Active:** Both instances are active simultaneously.  Better for scalability and stateless applications. Stateful applications require session data to be replicated or managed separately.

**IV.  Scaling: Meeting Demand Dynamically**

*   **The Problem of Growth:**  As the application's user base grows, demand on the servers increases.
*   **Two Scaling Approaches:**
    *   **Vertical Scaling:** Increasing the *size* (resources) of existing instances (e.g., moving from a t2.micro to a t2.large).
        *   **Limitations:**  There's an upper limit to how large an instance can be.  Requires stopping the instance to resize.
        *   **Process (for active-passive):** Stop passive instance, change size/type, start passive, switch traffic, repeat for the original active instance.  Manual and disruptive.
    *   **Horizontal Scaling:** Adding *more* instances of the same size.
        *   **Advantages:**  No practical limit to the number of instances.  Better aligns with the cloud's pay-as-you-go model.
        *   **Stateless Applications:** Horizontal scaling works best with stateless applications, where session data isn't tied to a specific server.
*   **Manual vs. Automated Scaling:**
    *   Manually launching and shutting down instances is inefficient and error-prone.
    *   **Solution: Amazon EC2 Auto Scaling**

**V.  Amazon EC2 Auto Scaling: Automated Horizontal Scaling**

*   **Core Function:** Automatically adds or removes EC2 instances based on defined conditions (metrics).
*   **Integration with CloudWatch:** Auto Scaling responds to CloudWatch alarms, which are triggered by metrics exceeding defined thresholds (e.g., CPU utilization).
*   **Benefits:**
    *   **On-Demand Capacity:** Provisions resources only when needed, optimizing costs.
    *   **Fleet Management:** Maintains the health of the instance fleet, automatically replacing unhealthy instances.
    *   **High Availability:** Ensures a minimum number of instances are always running.
*   **Key Components:**
    *   **1. Launch Template (or Launch Configuration - deprecated):** Defines *what* to launch.
        *   **Contents:** AMI ID, instance type, security group, key pair, storage (EBS volumes), resource tags, user data (scripts to run on instance launch).
        *   **Versioning:** Launch templates support versioning for rollbacks and managing updates.
        *   **Creation Methods:** From an existing instance, from an existing template, or from scratch.
    *   **2. Auto Scaling Group (ASG):** Defines *where* and *how many* instances to launch.
        *   **VPC and Subnets:** Specifies the network and Availability Zones.  *Always use at least two subnets in different AZs for high availability.*
        *   **Instance Purchase Options:** On-Demand, Spot, or a combination.
        *   **Capacity Settings:**
            *   **Minimum:** The lowest number of instances that will always be running.
            *   **Maximum:** The upper limit on the number of instances.
            *   **Desired Capacity:** The target number of instances. Auto Scaling adjusts to maintain this number.
        *   **Fleet Management:** If all three capacity settings are the same, Auto Scaling focuses on maintaining that number of healthy instances.
    *   **3. Scaling Policies:** Defines *when* to scale (add or remove instances).
        *   **Integration with CloudWatch Alarms:** Scaling policies are triggered by CloudWatch alarms.
        *   **Types of Scaling Policies:**
            *   **Simple Scaling:**  Adds or removes a fixed number of instances (or a percentage) based on a single alarm.  Includes a cooldown period to prevent rapid, unnecessary scaling.
            *   **Step Scaling:**  Allows for different scaling actions based on the severity of the alarm (e.g., add 1 instance at 60% CPU, add 2 at 80%, add 4 at 95%).  Responds to additional alarms even during scaling.
            *   **Target Tracking Scaling:**  Simplest to configure.  You specify a target value for a metric (e.g., average CPU utilization of 60%), and Auto Scaling automatically creates the necessary CloudWatch alarms and adjusts the instance count to maintain that target.  Good for CPU utilization, network utilization, and request count.
*   **Example Scenario (Demonstration):**
    *   Launch template configured to mirror existing web servers (Amazon Linux AMI, t2.micro, web security group, user data to install the application).
    *   Auto Scaling Group created: `app-asg`, using the launch template, in the `app-vpc`, across `private A` and `private B` subnets.
    *   Attached to an existing load balancer (target group: `app-target-group`).
    *   ELB health checks enabled.
    *   Minimum capacity: 2, Maximum capacity: 4, Desired capacity: 2.
    *   Target tracking scaling policy: `CPU utilization`, target value 60%, 300-second warmup.
    *   Stress test using the `/info` page's "stress CPU" feature to simulate load.
    *   CloudWatch alarm triggers, launching two new instances.
    *   Load balancer distributes traffic to the new instances.
    *   CPU utilization decreases.
    *   (If the load drops, instances would be terminated down to the minimum of 2).
* **Important Note:** When deleting, delete the *Auto Scaling Group*, not just the instances. Otherwise, the ASG will automatically launch new instances to maintain the desired capacity.

**VI. Elastic Load Balancing (ELB): Distributing Traffic**

*   **Purpose:** Distributes incoming application traffic across multiple targets (EC2 instances, containers, IP addresses, Lambda functions).
*   **High Availability and Scalability:** ELB is a regional, highly available, and automatically scaling service. You don't manage individual load balancer nodes.
*   **Types of Load Balancers:**
    *   **Application Load Balancer (ALB):**  For HTTP and HTTPS traffic (Layer 7).  Offers advanced routing capabilities.
    *   **Network Load Balancer (NLB):**  For TCP, UDP, and TLS traffic (Layer 4).  Handles very high throughput with low latency.
    *   **Gateway Load Balancer:**  For routing traffic to third-party virtual appliances.
*   **ALB Components:**
    *   **1. Listener:** Checks for connection requests.
        *   **Configuration:** Protocol (HTTP, HTTPS) and port (e.g., 80, 443).
        *   **Multiple Listeners:** A single ALB can have multiple listeners.
    *   **2. Target Group:** A group of backend targets.
        *   **Target Types:** EC2 instances, IP addresses, Lambda functions.
        *   **Health Checks:**  The load balancer checks the health of targets in the target group.  *Crucially, define meaningful health checks that verify the application's full functionality, not just port availability.* (e.g., a `/monitor` page that checks database and S3 connectivity).
    *   **3. Rules:**  Define how traffic is routed from listeners to target groups.
        *   **Default Rule:** Every listener has a default rule.
        *   **Additional Rules:**  Can route based on path (e.g., `/info`), host, headers, etc. (because ALB operates at Layer 7).
*   **ALB Features:**
    *   **Request-Based Routing:** Routes based on URL path, host, headers, method, source IP.
    *   **Direct Responses:** Can send fixed responses (e.g., custom HTML) or redirects directly to the client.
    *   **TLS Offloading:** Handles HTTPS encryption/decryption, reducing load on backend servers. Requires an SSL certificate (from IAM or ACM).
    *   **User Authentication:** Integrates with identity providers (OpenID Connect, SAML, LDAP, etc.).
    *   **Security Groups:** Control traffic allowed to the load balancer.
    *   **Routing Algorithms:**
        *   **Round Robin (Default):** Distributes requests evenly across targets.
        *   **Least Outstanding Requests:** Sends requests to the target with the fewest pending requests.  Better for targets with varying processing capabilities or requests with varying complexity.
    *   **Sticky Sessions (Session Affinity):**  Uses HTTP cookies to ensure requests from the same client are sent to the same target.  Useful for stateful applications.
*   **NLB Features:**
    *   **Protocols:** TCP, UDP, TLS (but doesn't understand HTTP/HTTPS).
    *   **Flow Hash Routing:** Routes based on protocol, source/destination IP and port, and TCP sequence number.
    *   **Sticky Sessions:** Based on source IP address (not cookies).
    *   **TLS Offloading:**  Can handle TLS encryption/decryption.
    *   **High Throughput:** Handles millions of requests per second with low latency *without needing to scale up*.
    *   **Static and Elastic IP Addresses:**  Supports static IP addresses, useful for applications that can't use DNS or require firewall rules based on IP.
    *   **Source IP Preservation:**  The backend servers see the client's original IP address (unlike ALB, where they see the load balancer's IP).
*   **Choosing Between ALB and NLB:**  See the provided table for a feature comparison. The choice depends on the application's specific requirements.
* **Example Scenario (Demonstration):**
    *   Create an Application Load Balancer: `app-elb`, internet-facing.
    *   VPC: `app-vpc`, Availability Zones: Both, Public Subnets: Both.
    *   Security Group: Allow traffic on port 80 from anywhere.
    *   Listener: Default HTTP on port 80.
    *   Target Group: `app-target-group`, target type: instances, default settings.
        *   Include the two existing EC2 instances (in private subnets) as targets.
    *   Create the load balancer.
    *   Access the application using the load balancer's DNS name.
    *   Test by refreshing the `/info` page to see traffic routed to both instances in different AZs.
* **ELB and Auto Scaling Integration**
    *     Auto Scaling informs ELB when the new instances are added or removed
    *     Health check from ELB to validate application
    *     Connection draining: when scale down, instances will be terminated after all connections end.

**VII. Conclusion: A Highly Available and Scalable Architecture**

By combining EC2 Auto Scaling and Elastic Load Balancing, we've created an infrastructure that is:

*   **Highly Available:** Redundant instances in multiple Availability Zones, with automatic failover.
*   **Scalable:** Automatically adjusts capacity to meet demand, both up and down.
*   **Cost-Effective:**  Only pays for the resources used.
*   **Resilient:**  Automatically replaces unhealthy instances.

This optimized architecture is a significant improvement over the initial single-instance setup, demonstrating the power of AWS services for building robust and efficient applications.
